README file for Programming Assignment 3 (C++ edition)
======================================================

Your directory should now contain the following files:

 Makefile                 -> [course dir]/src/PA3/Makefile
 README
 cool.y
 bad.cl
 good.cl
 cool-tree.handcode.h
 cool-tree.cc             -> [course dir]/src/PA3/cool-tree.cc
 cool-tree.aps            -> [course dir]/src/PA3/cool-tree.aps
 dumptype.cc              -> [course dir]/src/PA3/dumptype.cc
 handle_flags.c           -> [course dir]/src/PA3/handle_flags.cc
 parser-phase.cc          -> [course dir]/src/PA3/parser-phase.cc
 stringtab.cc             -> [course dir]/src/PA3/stringtab.cc
 tokens-lex.cc            -> [course dir]/src/PA3/tokens-lex.cc
 tree.cc                  -> [course dir]/src/PA3/tree.cc
 utilities.cc             -> [course dir]/src/PA3/utilities.cc
 *.d                      dependency files
 *.*                      other generated files

The include (.h) files for this assignment can be found in 
[course dir]/include/PA3

        The Makefile contains targets for compiling and running your
        program. DO NOT MODIFY.
    
        The README contains this info. Part of the assignment is to
        fill in the README with the write-up for your project. You should
        explain design decisions, explain why your code is correct, and why
        your test cases are adequate. It is part of the assignment to
        clearly and concisely explain things in text as well as to comment
        your code. Just edit this file.

        cool.y is the skeleton for the parser specification that you
        are to write. It already contains productions for the program
        and the classes. Use them as an example to write the remaining
        productions.  You should also read the bison documentation.
        This skeleton will compile and run as is, but it doesn't
        do much.

        good.cl, bad.cl test a few features of the grammar. You should
        add tests to ensure that good.cl exercises every legal
        construction of the grammar and that bad.cl exercises as many
        different parsing errors as you can squeeze into one file.

        cool-tree.aps contains the definitions for the tree language
        which you use to construct the abstract syntax tree (AST).
        From this file, cool-tree.h and cool-tree.cc are automatically 
        generated by a utility that compiles the specification into
        C++ functions for producing and consuming the tree nodes.
        This file is provided for your reference.  DO NOT MODIFY.

        tree.{cc|h} contain definitions used by the tree package.
        cool-tree.handcode.h is the handwritten extension to
        cool-tree.h.  If you read cool-tree.h and cool-tree.cc, you will
        note that there are "hooks" for extending the classes
        declarations.  Extending and modifying the tree package is
        discussed in the "Cool Tour", but you do not need to (and should
        not) modify the tree package for this assignment.

        tokens-lex.cc is a lexer capable of reading a token stream from
        console in the format produced by the lexer phase. DO NOT
        MODIFY.

        parser-phase.cc contains a driver to test the parser. DO NOT
        MODIFY.

        dumptype.cc prints the AST out in a form readable by the
        semant phase of the compiler. DO NOT MODIFY.

        handle_flags.cc implements routines for parsing command line
        flags. DO NOT MODIFY.

        The rest of the files are created as byproducts of `bison'.
        `cool-parse.cc' is the generated C++ file containing the
        parser.

        Files not discussed are covered in the README for PA2.

Instructions
------------

        To compile your parser program type:

        % gmake parser

        This produces an executable named "parser" which is standalone
        phase of the Cool compiler.  It requires lexer, semant, and cgen
        to do anything useful.

        To test your parser on a file 'foo.cl' type

        % myparser foo.cl

        myparser is a shell script that "glues" together lexer and
        parser using pipes.

        To run your parser on the files good.cl and bad.cl type:

        % gmake dotest

        If you think your parser is correct and behaves like
        the one we wrote, you may want to run a COOL compiler using
        your parser:

        % mycoolc foo.cl

        To overwrite the default lexical analyzer with yours, replace 
        lexer (which is a symbolic link to the "official" lexer) with
        your lexer from PA2.

        To turnin your work type:

        % gmake submit-clean

        And run the "submit" program following the instructions on the
        course web page.

        Running "submit" will collect the files cool.y, good.cl, bad.cl,
        good.output, bad.output, and README. Don't forget to edit the
        README file to include your write-up, and to write your own test
        cases in good.cl and bad.cl.

        You may turn in the assignment as many times as you like.
        However, only the last version will be retained for
        grading.

        If you change architectures you must issue

        % gmake clean

        when you switch from one type of machine to the other.
        If at some point you get weird errors from the linker,
        you probably forgot this step.

        GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA3
----------------

Analisador de bisão completo (para meus propósitos) para linguagem legal. A configuração é para OSX.

Declarações multi dec let não são suportadas
Nenhum tratamento de número de linha especial é feito (padrão de bisão)

cool.y: Começamos definindo tipos para todos os não terminais das gramáticas. Em seguida, declaramos a precedência e a associatividade para cada operação. É aqui que a maioria dos nossos conflitos de mudança / redução foram corrigidos. Escolhemos a precedência esquerda para a maioria das operações da esquerda para a direita. Algumas exceções notáveis ​​são as operações de comparação, atribuição e negação. Também declaramos uma regra de precedência para uso em uma regra de produção. Em seguida, definimos todas as regras gramaticais, em conformidade, tanto quanto possível, para o manual legal. Começamos no maior programa não terminal, e seguimos até os terminais na expressão não terminal. Retiramos todas as funções AST de cool-tree.cc. Para verificação de erros, adicionamos casos específicos para determinados não terminais. Isso nos permitiu detectar e recuperar a maioria dos erros. Nosso analisador na verdade detecta mais erros do que o de Stanford e os detecta mais corretamente em alguns casos. Como as instruções nos disseram, ignoramos erros nas definições de classe após O primeiro. Para erros dentro de expressões, usamos yyerrok para que bison continuasse a analisar imediatamente após o erro e fornecesse todos os erros na expressão. Nossos números de linha funcionam para erros devido ao fato de que os números de linha vêm do lexer. No entanto, os números das linhas não estão sendo informados corretamente na AST devido a erros além do nosso controle. A variável curr_lineno está gerando um erro de redeclaração que não pode ser anexado a nenhum arquivo único. Por isso, não incluímos nenhum " Chamadas @ $ "ou" NODELOC () "em nossas regras gramaticais. Nosso AST impresso será diferente do analisador de Stanford por um número com um hash na frente dele. Isso não é um erro com nosso código. Nossa saída de analisador também será diferente em os erros que encontra pelas razões explicadas acima.

parser_test_files / *: conforme explicado acima, esses arquivos testam a correção na análise ou verificação de erros. Consulte acima para obter detalhes sobre o que cada arquivo deve ser. Os arquivos BAD têm comentários em cada linha que deve gerar um erro. Veja estes para obter detalhes ao comparar o arquivo e a saída do analisador.

Sobre
módulo analisador

Recursos
 Leia-me
Lançamentos
Nenhum lançamento publicado
Pacotes
Nenhum pacote publicado
Colaboradores 4
@benjlouie
benjlouie Ben Louie
@DraftiestHat
DraftiestHat Matthew Karasz
@Ruzyho
Floresta Ruzyho
@haekuh
haekuh
línguas
C ++
87,7%
 
Yacc
12,3%
